# embedding_cosinesimilarity_test
RAGの実験のために、ベクトル化とコサイン類似度のテストをしました。<br>

サンプルの文書をベクトル化し、コサイン類似度を計算するということをテストしました。<br>
pythonの環境を使っています。EmbeddingのモデルはAzure OpenAI Serviceのtext-embedding-3-largeとtext-embedding-3-smallです。<br>
PythonのOpenAIのAPIを使うためのライブラリが、新しくなっており、関数や引数の名前で少し苦労としたので、メモを残します。<br>
openaiのライブラリはVersion: 1.70.0です。

## 結果
text-embedding-3-largeを使った時、コサイン類似度で次のような結果が得られます。

|ベクトル1|ベクトル2|値|
|:------|:-------|:--|
|プロンプト|候補1|0.5854|
|プロンプト|候補2|0.6143|

環境を構築し、コードを用意します。

## 0.環境設定
私は仮想環境を使います。仮想環境を使わない方は1.をご覧ください。<br>
新しい環境を構築。
```bash
python -m venv <新しい仮想環境ディレクトリ>
```
仮想環境有効化。
```
source bin/activate
```

### 1.必要なモジュールをインストール
openaiのモジュールをインストール。<br>
類似度計算でcosinやベクトルの内積を計算するのでnumpyも必要。
```bash
pip install openai numpy
```

## 2.プロンプトの選定
プロンプトと、類似度を計算する文書を2つ用意しました。

|種類|内容|
|:--|:---|
|プロンプト|SharePoint Onlineの検索の事例を探してください|
|候補1|また、クラウドストレージ（SharePoint Online）標準の検索機能では、全文検索や横断検索など、求めている十分な検索が行えなかったこともあり、それらを解決する精度の高い検索システムを探す必要がありました。特に技術文書などの検索に重きを置いている、設計・施工部門からの要望もあり、課題解決のためのツールの検討を開始しました。1.取り組みの背景 - Neuron ES 導入後の評価 - ”仕事のテンポを止めない” 検索ストレスが低減し、業務効率UP！ ◆ クラウドストレージへの移行に伴いデータの所 在が分散したが、検索システムによってそれを意識することなく欲しい情報に辿り着けている◆ 自社システムとのAPI連携により、従業員に新た な利用価値創出 導入事例：大和ハウス工業株式会社SharePoint Onlineの検索性向上にNeuron ESを導入。さらに既存の業務システムとのAPI連携によって、新たな利用価値を創出。大和ハウス工業株式会社|
|候補2|特に、現在はクラウドストレージへの移行期であるため、従業員が新旧どちらのストレージにファイルが保存されてるかを意識する必要もなく、しかもスピーディに目的のファイルを見つけられるようになったため、以前と比べて利便性自体も高くなったと感じています。また、SharePoint Online標準の検索では精度が不十分であった全文検索にも対応したので、社内規定やマニュア ル、申請書といった書類を検索するのにも役立っています。全文検索：ファイル内のすべての文章を対象とする検索のこと社内業務システムともAPI連携を行い 検索を軸とした新たな可能性や価値を創出今回の導入では、SharePoint Online上の検索性能を単に向上させただけでなく、従業員への通達（連絡）に利用する社内業務システムを刷新する際に「Neuron Enterprise Search」を検索エンジンとして組み込みました。これによって検索精度が向上しただけではなく、添付ファイルの全文検索も可能となりました。こうしたAPI連携の機能が提供されていることで、検索を軸とした新たな可能性や価値の創出ができるのも面白いと感じています|

## 3. Azure OpenAI ServiceでAPIを用意
Azur PortalからAzure AI Foundryを開き、text-embedding-3-largeとtext-embedding-3-smallをデプロイします。<br>
uri、キーなどを使います。

## 4.サンプルプログラムの作成
プログラムはebmedding.py[./ebmedding.py]をご覧ください。<br>
コードで苦労したところをメモします。

### 4-1.openaiのライプラリの読み込み
`imprt openai`ではエラーになったので、下記にします。
```
from openai import AzureOpenAI
```
### 4-2.クライアント作成
Azure AI Foundryでモデルをデプロイした画面から、ターゲットURIを参照し、エンドポイントとバージョン、apiキーを記載します。
client = AzureOpenAI(azure_endpoint="https://<ターゲットURI参照>.openai.azure.com",
api_version="<バージョン>",
api_key="<apiキー>")

### 4-3. Embeddingモデルを指定
deployment_idでの指定がうまくいかなかったので、`model_id`にモデル名を入力することで通りました。
```
model_id = "text-embedding-3-large" #利用するモデル名
```

### 4-4. 埋め込みベクトルの生成関数
作成したclientを使うようにします。
```
def get_embedding(text):
    response = client.embeddings.create(input=[text],model = model_id)
    return response.data[0].embedding
```

## 5.出力例

```
プロンプト:SharePoint Onlineの検索の事例を探してください

候補1:また、クラウドストレージ（SharePoint Online）標準の検索機能では、全文検索や横断検索など、求めている十分な検索が行えなかったこともあり、それらを解決する精度の高い検索システムを探す必要がありました。特に技術文書などの検索に重きを置いている、設計・施工部門からの要望もあり、課題解決のためのツールの検討を開始しました。1.取り組みの背景 - Neuron ES 導入後の評価 - ”仕事のテンポを止めない” 検索ストレスが低減し、業務効率UP！ ◆ クラウドストレージへの移行に伴いデータの所 在が分散したが、検索システムによってそれを意識することなく欲しい情報に辿り着けている◆ 自社システムとのAPI連携により、従業員に新た な利用価値創出 導入事例：大和ハウス工業株式会社SharePoint Onlineの検索性向上にNeuron ESを導入。さらに既存の業務システムとのAPI連携によって、新たな利用価値を創出。大和ハウス工業株式会社

候補2:特に、現在はクラウドストレージへの移行期であるため、従業員が新旧どちらのストレージにファイルが保存されてるかを意識する必要もなく、しかもスピーディに目的のファイルを見つけられるようになったため、以前と比べて利便性自体も高くなったと感じています。また、SharePoint Online標準の検索では精度が不十分であった全文検索にも対応したので、社内規定やマニュアル、申請書といった書類を検索するのにも役立っています。全文検索：ファイル内のすべての文章を対象とする検索のこと社内業務システムともAPI連携を行い検索を軸とした新たな可能性や価値を創出今回の導入では、SharePoint Online上の検索性能を単に向上させただけでなく、従業員への通達（連絡）に利用する社内業務システムを刷新する際に「Neuron Enterprise Search」を検索エンジンとして組み込みました。これによって検索精度が向上しただけではなく、添付ファイルの全文検索も可能となりました。こうしたAPI連携の機能が提供されていることで、検索を軸とした新たな可能性や価値の創出ができるのも面白いと感じています

Similarity between プロンプト and 候補1: 0.5854
Similarity between プロンプト and 候補2: 0.6143
モデル:text-embedding-3-large
```

## 6.比較
largeとsmallで比較します。<br>
<br>

モデル：text-embedding-3-large
|ベクトル1|ベクトル2|値|
|:------|:-------|:--|
|プロンプト|候補1|0.5854|
|プロンプト|候補2|0.6143|

モデル:text-embedding-3-small
|ベクトル1|ベクトル2|値|
|:------|:-------|:--|
|プロンプト|候補1|0.6175|
|プロンプト|候補2|0.6183|

<br>
どちらのモデルでも0.7以下の値。smallの方が若干値が高い。

## 7.追加テスト
Difyで検索テストした結果を記載します。同じプロンプトに基づいてナレッジのヒット効果をテストしました。候補1と候補2のスコアは下記です。

### 条件1：ベクトル検索のみ
ハイブリッド検索の設定はウェイト設定にし、セマンティックマッチングを1にします。
|ベクトル1|ベクトル2|スコア|
|:------|:-------|:--|
|プロンプト|候補1|0.59|
|プロンプト|候補2|0.59|

スコアはコサイン類似度の値と近い数字になっています。

### 条件2：ハイブリッド検索
ハイブリッド検索の設定はウェイト設定にし、セマンティックマッチング0.7, キーワードマッチング0.3にします。
|ベクトル1|ベクトル2|スコア|
|:------|:-------|:--|
|プロンプト|候補1|0.47|
|プロンプト|候補2|0.44|

キーワードマッチング入れることでスコアは全体的に下がりました。

### 条件３：ハイブリッド検索（リランク利用）
ハイブリッド検索の設定はRerank設定にし、cohereのrerank-multilingual-v3.0を利用します。
|ベクトル1|ベクトル2|スコア|
|:------|:-------|:--|
|プロンプト|候補1|0.99|
|プロンプト|候補2|0.44|

上記の結果から、Rerankモデルを利用することでスコアが大きくなるチャンクが出てくることがわかりました。
回答精度向上につながると考えられますが、また別の実験を検討したいと思います。
